{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789af4f-1455-42b3-9a30-d5b6650d8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d95c2-ced7-401b-a947-498875f983b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "radius = 2               \n",
    "n_bits = 2048            \n",
    "df = pd.read_csv(\"Dataset/AD.csv\")\n",
    "smiles_list = df[\"SMILES\"].tolist()\n",
    "morgan_data = []\n",
    "invalid_smiles = []\n",
    "for smiles in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        invalid_smiles.append(smiles)\n",
    "        continue\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    bit_arr = [int(x) for x in fp]\n",
    "    morgan_data.append([smiles] + bit_arr)\n",
    "columns = [\"SMILES\"] + [f\"bit_{i}\" for i in range(n_bits)]\n",
    "morgan_df = pd.DataFrame(morgan_data, columns=columns)\n",
    "morgan_df.to_csv(\"res_morgan_fingerprint_AD.csv\", index=False)\n",
    "merged_df = pd.concat([df, morgan_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75fba4-0a02-4fcc-98dd-0eed4581311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "radius = 2              \n",
    "n_bits = 2048            \n",
    "df = pd.read_csv(\"Dataset/TEST2.csv\")\n",
    "smiles_list = df[\"SMILES\"].tolist()\n",
    "morgan_data = []\n",
    "invalid_smiles = []\n",
    "for smiles in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        invalid_smiles.append(smiles)\n",
    "        continue\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    bit_arr = [int(x) for x in fp]\n",
    "    morgan_data.append([smiles] + bit_arr)\n",
    "columns = [\"SMILES\"] + [f\"bit_{i}\" for i in range(n_bits)]\n",
    "morgan_df2 = pd.DataFrame(morgan_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8c513-91d6-4ddf-9e1e-2a73c8b84357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "label = merged_df.iloc[:, 1]\n",
    "features = merged_df.iloc[:, 3:]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, label, test_size=0.2, stratify=label, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "search_spaces = {\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 3, 5]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 5, 10],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"max_features\": [\"auto\", \"sqrt\"]\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(solver='liblinear'),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": randint(3, 10),\n",
    "            \"learning_rate\": uniform(0.01, 0.2),\n",
    "            \"subsample\": uniform(0.6, 0.4),\n",
    "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
    "            \"gamma\": uniform(0, 0.5)\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5],\n",
    "            \"subsample\": [0.6, 0.8, 1.0]\n",
    "        },\n",
    "        \"method\": \"grid\"\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"model\": cb.CatBoostClassifier(verbose=False, random_state=42),\n",
    "        \"params\": {\n",
    "            \"iterations\": [100, 200],\n",
    "            \"depth\": [3, 5, 7],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"l2_leaf_reg\": [1, 3, 5],\n",
    "            \"bagging_temperature\": [0, 1, 3]\n",
    "        },\n",
    "        \"method\": \"random\"\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_params = {}\n",
    "\n",
    "for name, config in search_spaces.items():\n",
    "    print(f\"\\n {name} ...\")\n",
    "    if config[\"method\"] == \"grid\":\n",
    "        searcher = GridSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        searcher = RandomizedSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_distributions=config[\"params\"],\n",
    "            n_iter=30,\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    searcher.fit(X_train, y_train)\n",
    "    best_model = searcher.best_estimator_\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_Params\": searcher.best_params_,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "    best_params[name] = searcher.best_params_\n",
    "\n",
    "    print(f\" {name}  AUC: {auc:.4f}\")\n",
    "    print(f\"  {searcher.best_params_}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model_best_params_auc_ad.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"\\n:\\n\")\n",
    "import pprint\n",
    "pprint.pprint(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b02bfe-6048-409f-be62-47877dadf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pprint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "label = merged_df.iloc[:, 1]\n",
    "features = merged_df.iloc[:, 3:]\n",
    "\n",
    "binary_classes = sorted(label.unique())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, label, test_size=0.2, stratify=label, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "best_params = pd.read_csv(\"model_best_params_auc_ad.csv\", index_col=\"Model\")\n",
    "best_params_dict = best_params['Best_Params'].apply(eval).to_dict()\n",
    "\n",
    "\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42, **best_params_dict[\"DecisionTree\"]),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, **best_params_dict[\"RandomForest\"]),\n",
    "    'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=200, random_state=42, **best_params_dict[\"LogisticRegression\"]),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, **best_params_dict[\"XGBoost\"]),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42, **best_params_dict[\"GradientBoosting\"]),\n",
    "    'CatBoost': cb.CatBoostClassifier(verbose=False, random_state=42, **best_params_dict.get(\"CatBoost\", {}))\n",
    "}\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "def evaluate_model(model, model_name, threshold=0.5):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=binary_classes, yticklabels=binary_classes)\n",
    "    plt.title(f'{model_name} Confusion Matrix (Threshold={threshold})')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.svg', format='svg')\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})', lw=2)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.title(f'{model_name} ROC Curve', fontsize=14)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name}_roc_curve.svg\", format='svg')\n",
    "    plt.close()\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc = evaluate_model(model, model_name, threshold=0.5)\n",
    "    print(f\"{model_name} AUC: {auc:.4f}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model_evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aca90d-8e3c-48e9-a38a-2a60e555827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = morgan_df2.iloc[:, 1:]\n",
    "rf_model = models[\"CatBoost\"]  \n",
    "pred_labels = rf_model.predict(new_features)\n",
    "pred_probs = rf_model.predict_proba(new_features)[:, 1]\n",
    "threshold = 0.5\n",
    "pred_labels_custom = (pred_probs >= threshold).astype(int)\n",
    "df22 = pd.read_csv(\"Dataset/TEST2.csv\")\n",
    "df22[\"Predicted_Label\"] = pred_labels_custom\n",
    "df22[\"Predicted_Probability\"] = pred_probs\n",
    "df22.to_csv(\"prediction_results_AD.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
